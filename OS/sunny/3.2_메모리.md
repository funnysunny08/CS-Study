# 메모리 계층

CPU가 메모리에 더 빨리 접근하게 하기 위해 메모리를 계층화시켰다!

https://github.com/funnysunny08/Algorithm-java/assets/88873302/82d2e802-b262-491c-b51b-099bc576fd33

- **레지스터:** CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적다.
- **캐시:** L1, L2 캐시를 지칭한다. 휘발성, 속도 빠름, 기억 용량이 적다. 참고로 L3 캐시도 있다.
- **주기억장치:** RAM을 가리킨다.
- **보조기억장치:** HDD, SSD를 일컬으며 비휘발성, 속도 낮음, 기억 용량이 많다.

## 레지스터(Register)

**레지스터란? *CPU가 요청을 처리하는데 필요한 데이터를 일시적으로 저장하는 기억장치!***

CPU는 자체적으로 데이터를 저장할 방법이 없으므로 메모리로 직접 데이터를 전송할 수 없다. 

👉 그렇기 때문에 연산을 위해서는 반드시 레지스터를 거쳐야 하며, 이를 위해 레지스터는 특정 주소를 가리키거나 값을 읽어올 수 있다!

프로세서에 위치하고 있으며, 프로세스가 바로 사용할 수 있는 데이터 (소량의 데이터, 처리 중인 중간 결과 등)를 담고 있는 영역!

https://github.com/funnysunny08/Algorithm-java/assets/88873302/02c5dd0b-301f-40c5-a8b3-2d9c48b1eeb3

## 캐시(Cache)

**캐시란? *데이터를 미리 복사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리!***

캐시를 통해 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고, 
무언가를 다시 계산하는 시간을 절약할 수 있다!!

또한 속도가 빠른 장치와 느린 장치 사이에서 속도차에 따른 병목 현상을 완화하기 위한 범용 메모리로서 사용한다!

### CPU 캐시

*💡 대용량의 메인 메모리 접근을 빠르게 하기 위해 CPU 칩 내부나 바로 옆에 탑재하는 작은 메모리*

| 종류 | 설명 | CPU 성능에 직접적인 영향 |
| --- | --- | --- |
| L1 캐시 | 일반적으로 CPU 칩 안에 내장되어 데이터 사용 및 참조에 가장 먼저 사용되는 캐시 메모리 | O |
| L2 캐시 | - L1 캐시 메모리와 용도와 역할이 비슷
- 속도: L1 캐시 > L2 캐시 > 일반 메모리(RAM) | O |
| L3 캐시 | - L1 캐시, L2 캐시와 동일한 원리로 작동
- 대부분 CPU가 아닌 메인보드에 내장 | X |
- 실제로 메모리와 CPU 사이의 속도 차이가 너무 크기 때문에 그 중간에 레지스터 계층을 둬서 속도 차이를 해결한다!
- 👉 이렇게 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 **캐싱 계층**이라고 한다.

> **캐싱(Caching):** 캐시라고 하는 좀 더 빠른 메모리 영역으로 데이터를 가져와서 접근하는 방식
> 

### 지역성의 원리

*🤔 그렇다면 캐시 계층을 두는 것 말고 캐시를 직접 설정할 때는 어떻게 해야 할까?*

💡 이는 지역성에 기반하여 설정한다!!!

- **시간 지역성 :** 최근 사용한 데이터에 다시 접근하려는 특성
- **공간 지역성 :** 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

### 캐시히트와 캐시미스

이렇게 캐시에서 원하는 데이터를 찾았다면 ?! 👉 **캐시히트**

해당 데이터가 캐시에 없어서 주메모리로 가서 데이터를 찾아와야 한다면 ?! 👉 **캐시미스**

### 캐시매핑

캐시매핑이란, 캐시가 히트되기 위해 매핑하는 방법을 말하며 CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명한다.

| 이름 | 설명 |
| --- | --- |
| 직접 매핑 
(directed mapping) | 메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20 … 이런 식으로 매핑하는 것을 말한다. 처리가 빠르지만 충돌 발생이 잦다. |
| 연관 매핑
(associative mapping) | 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑한다. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느리다. |
| 집합 연관 매핑
(set associative mapping) | 직접 매핑과 연관 매핑을 합쳐 놓은 것. 순서는 일치시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색은 좀 더 효율적이다. |

### 웹 브라우저의 캐시

소프트웨어적인 대표적인 캐시로는 웹 브라우저의 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지가 있다!

이러한 것들은 보통 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 쓰인다

- **쿠키**
    - 만료기한이 있는 키-값 저장소
- **로컬 스토리지**
    - 만료기한이 없는 키-값 저장소
- **세션 스토리지**
    - 만료기한이 없는 키-값 저장소

### 데이터베이스의 캐싱 계층

데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 ‘캐싱 계층’으로 둬서 성능을 향상시키기도 한다!

https://github.com/funnysunny08/Algorithm-java/assets/88873302/15b3a0ec-a25e-4f7a-89d4-c8326d9bb8a8

## 메인 메모리(Main Memory)

***메인 메모리는 주기억장치로 컴퓨터에서 수치, 명령, 자료 등을 기억하는 컴퓨터 하드웨어 장치다!***

### RAM(Random Access Memory)

- 컴퓨터가 빠른 액세스를 하기 위해 데이터를 단기간 저장하는 구성 요소
- 사용자가 요청하는 프로그램이나 문서를 스토리지 디스크에서 메모리로 로드하여 각각의 정보에 액세스한다
- 휘발성 기억 장치로 전원이 유지되는 동안 CPU의 연산 및 동작에 필요한 모든 내용이 저장된다
- `Random Access` 👉 어느 위치에서든 똑같은 속도로 접근하여 읽고 쓸 수 있다는 의미

### ROM(Read Only Memory)

- 컴퓨터에 지시사항을 영구히 저장하는 비휘발성 메모리 (고정 기억 장치)
- 변경 가능성이 희박한 기능 및 부품에 사용

## 하드 디스크 드라이브(Hard Disk Drive, HDD)

***HDD란?! 비휘발성, 순차접근이 가능한 컴퓨터의 보조 기억 장치***

비휘발성 데이터 저장소 가운데 가장 대중적이며 용량 대비 가격이 가장 저렴!!

> **HDD의 작동 원리**
> 
> - 보호 케이스 내부의 플래터를 회전 → 플래터에 자기 패턴으로 정보 기록
> - 플래터 표면의 코팅된 자성체에 데이터 기록
> - 회전하는 플래터 위에 부상하는 입출력 헤드에 의해 자기적으로 데이터 기록 및 조회 가능

# 메모리 관리

## 가상 메모리(Virtual Memory)

***가상 메모리는 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것!!***

애플리케이션이 실행될 때, 실행에 필요한 일부분만 메모리에 올라가며 애플리케이션의 나머지는 디스크에 남게 된다. 

즉, 디스크가 RAM의 보조 기억장치(backing store)처럼 작동하는 것!!

👉 결국 빠르고 작은 기억장치(RAM)을 크고 느린 기억장치(디스크)와 병합하여, **하나의 크고 빠른 기억장치(가상 메모리)**처럼 동작하게 하는 것!!

이러한 가상 메모리를 구현하기 위해서는 컴퓨터가 특수한 메모리 관리 하드웨어를 갖추고 있어야만 한다!! 👉 **MMU (Memory Mangement Unit)**

> **MMU (Memory Management Unit)**
> 
> - MMU는 가상주소를 물리주소로 변환하고, 메모리를 보호하는 기능을 수행
> - MMU를 사용하게 되면, CPU가 각 메모리에 접근하기 이전에 메모리 주소 번역 작업이 수행됨
> - 그러나 메모리를 일일이 가상 주소에서 물리적 주소로 번역하게 되면 작업 부하가 너무 높아지므로, MMU는 RAM을 여러 부분(페이지, pages)로 나누어 각 페이지를 하나의 독립된 항복으로 처리함
> - 페이지 및 주소 번역 정보를 기억하는 작업이 가상 메모리를 구현하는 데 있어 결정적인 절차다!

### 요구 페이징(Demand Paging)이란?

CPU가 요청할 때 프로세스의 데이터를 RAM에 올리는 것을 의미한다!!

즉, 프로세스의 모든 데이터를 메모리에 올리지 않는다!

### 스와핑

만약 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생한다!!

이때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 스와핑(swapping)이라고 한다. 

👉 이를 통해 마치 페이지 폴트가 일어나지 않은 것처럼 만든다!!

### 페이지 폴트(Page Fault)

페이지 폴트란 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생한다.

> 🤔 **페이지 폴트와 그로 인한 스와핑 과정**
> 
> 1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제 알린다.
> 2. 운영체제는 CPU의 동작을 잠시 멈춘다.
> 3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾는다. 물리 메모리에도 없다면 스와핑이 발동한다.
> 4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화한다.
> 5. 중단되어있던 CPU를 다시 시작한다.

### TLB(Translation Lookaside Buffer, 페이지 정보 캐시)

*TLB는 가상 메모리 주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용하는 캐시로, 최근에 일어난 가상 메모리와 물리 주소의 변환 테이블을 저장해둔다!!*

CPU가 가상 주소를 가지고 메모리에 접근하려고 할 때 우선은 TLB에 접근하여 가상 주소에 해당되는 물리 주소를 찾고, 만약 TLB에 매핑이 존재하지 않는다면 MMU가 페이지 테이블에서 해당되는 물리 주소로 변환한 후 메모리에 접근하게 된다!

## 쓰레싱(Thrashing)

*쓰레싱은 **메모리 영역에 접근하게 될 때, 메모리에 페이지 부재(=페이지 폴트(Page fault)율이 높은 것**을 의미하며, 심각한 성능 저하를 초래한다!*

https://github.com/funnysunny08/Algorithm-java/assets/88873302/71a98d40-2839-4516-a216-cb1feb6acf3d

활발하게 사용되는 페이지 집합을 지원해줄 만큼 프레임이 충분히 할당받지 못한 프로세스는 페이지 폴트가 발생하게 된다!

이때, 페이지 교체가 필요하지만 이미 활발히 사용되는 페이지들만으로 이루어져 있으므로 어떤 페이지가 교체되던 바로 다시 페이지 교체가 필요하게 될 것 이다!

결과적으로 바로 반복해서 페이지 폴트가 발생하며, 교체된 페이지는 또 다시 얼마 지나지 않아 읽어올 필요가 생기게 된다. 

**👉 이렇게 과도한 페이징 작업을 쓰레싱이라 한다!!**

### 쓰레싱 현상 방지 방법

- **작업 세트(working set)**
    - 프로세스의 과거 사용 이력인 지역성(locality)을 통해 결정된 페이 집합을 만들어서 미리 메모리에 로드하는 것
    - 미리 메모리에 로드하면 탐새에 드는 비용을 줄일 수 있고 스와핑 또한 줄일 수 있다
- **PFF(Page Fault Frequency)**
    - 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법
    - 만약 상한선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄이는 것

## 메모리 할당

메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당한다 👉 ***연속 할당 VS 불연속 할당***

### 연속 할당

*메모리에 ‘연속적으로’ 공간을 할당하는 것*

- **고정 분할 방식(Fixed Partition Allocation)**
    - 메모리를 미리 나누어 관리하는 방식
    - 메모리가 미리 나뉘어 있기 때문에 융통성이 없다
    - 내부 단편화 발생
        - **내부 단편화 :** 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
- **가변 분할 방식(Variable Partition Allocation)**
    - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용
    - 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있다.
        - **외부 단편화 :** 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
    - 최초적합(first fit), 최적적합(best fit), 최악적합(worst fit)이 있다
    
    | 이름 | 설명 |
    | --- | --- |
    | 최초적합 | 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당 |
    | 최적적합 | 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당 |
    | 최악적합 | 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당 |
    - **홀 :** 할당할 수 있는 비어 있는 메모리 공간

### 불연속 할당

*메모리에 ‘불연속적으로’ 공간을 할당하는 것*

- **페이징(Paging)**
    - 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당한다
    - 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해진다
- **세그멘테이션(Segmentation)**
    - 페이지 단위가 아닌 의미 단위인 세그먼트(Segment)로 나누는 방식
    - 공유와 보안 측면에서 좋으며 홀 크기가 균일하지 않은 문제가 발생
- **페이지드 세그멘테이션(Paged Segmentaion)**
    - 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것

## 페이지 교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 일어나며, 이러한 스와핑이 많이 일어나지 않도록 설계되어야 한다!

이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어난다!!

### 오프라인 알고리즘(Offline Algorithm)

- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘 👉 가장 좋은 방법!
- But, 현실적으로 불가능

### FIFO(First In First Out)

가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

### LRU(Least Recentle Used)

참조가 가장 오래된 페이지를 바꾸는 방법

‘오래된’ 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어햐 하는 문제점이 있다.

### LFU(Least Frequently Used)

가장 참조 횟수가 적은 페이지를 교체하는 방법